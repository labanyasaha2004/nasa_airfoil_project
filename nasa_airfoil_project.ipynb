{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1146a4dd-1a79-44dd-afdb-b4dc10d292fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   Frequency  AngleOfAttack  ChordLength  FreeStreamVelocity  \\\n",
      "0      800.0            0.0       0.3048                71.3   \n",
      "1     1000.0            0.0       0.3048                71.3   \n",
      "2     1250.0            0.0       0.3048                71.3   \n",
      "3     1600.0            0.0       0.3048                71.3   \n",
      "4     2000.0            0.0       0.3048                71.3   \n",
      "\n",
      "   SuctionSideDisplacement  SoundLevel  \n",
      "0                 0.002663     126.201  \n",
      "1                 0.002663     125.201  \n",
      "2                 0.002663     125.951  \n",
      "3                 0.002663     127.591  \n",
      "4                 0.002663     127.461  \n",
      "Q1. Total rows in the dataset: 1522\n",
      "Q2. Rows after dropping duplicates: 1503\n",
      "Q3. Rows after dropping duplicates and nulls: 1499\n",
      "Columns in the dataset after cleaning:\n",
      "Index(['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity',\n",
      "       'SuctionSideDisplacement', 'SoundLevel'],\n",
      "      dtype='object')\n",
      "Q4. Renamed 'SoundLevel' to 'PressureLevel'\n",
      "Q5. Parquet file created: clean_airfoil_data.parquet\n",
      "Q6. Rows in cleaned Parquet dataset: 1499\n",
      "Q11. Mean Squared Error: 24.652407143948416\n",
      "Q12. Mean Absolute Error: 3.818793736150522\n",
      "Q13. R Squared: 0.46810668156463275\n",
      "Q14. Intercept: 132.48211351023826\n",
      "Q15. Number of stages in the pipeline: 3\n",
      "\n",
      "Q16-Q20. Coefficients for each feature:\n",
      "Coefficient for Frequency: -0.0013180160695473984\n",
      "Coefficient for AngleOfAttack: -0.3824161369629376\n",
      "Coefficient for ChordLength: -34.94142726943928\n",
      "Coefficient for FreeStreamVelocity: 0.10512354193547373\n",
      "Coefficient for SuctionSideDisplacement: -159.23292694165167\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset using your path\n",
    "df = pd.read_csv(r\"C:\\Users\\labanya\\OneDrive\\Documents\\Desktop\\COLLEGE\\PROJECT\\DATASET\\NASA_airfoil_noise_raw.csv\")\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Q1: How many rows are present in the dataset?\n",
    "rows_original = len(df)\n",
    "print(\"Q1. Total rows in the dataset:\", rows_original)\n",
    "\n",
    "# Q2: How many rows are present in the dataset after dropping duplicates?\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "rows_no_duplicates = len(df_no_duplicates)\n",
    "print(\"Q2. Rows after dropping duplicates:\", rows_no_duplicates)\n",
    "\n",
    "# Q3: How many rows are present in the dataset after dropping duplicates and rows with null values?\n",
    "df_cleaned = df_no_duplicates.dropna()\n",
    "rows_cleaned = len(df_cleaned)\n",
    "print(\"Q3. Rows after dropping duplicates and nulls:\", rows_cleaned)\n",
    "\n",
    "# Remove extra spaces in column names (if any)\n",
    "df_cleaned.columns = df_cleaned.columns.str.strip()\n",
    "\n",
    "# Check the column names\n",
    "print(\"Columns in the dataset after cleaning:\")\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "# Q4: Rename 'SoundLevel' to 'PressureLevel' if it exists\n",
    "if 'SoundLevel' in df_cleaned.columns:\n",
    "    df_cleaned = df_cleaned.rename(columns={'SoundLevel': 'PressureLevel'})\n",
    "print(\"Q4. Renamed 'SoundLevel' to 'PressureLevel'\")\n",
    "\n",
    "# Q5: Save cleaned data as Parquet file\n",
    "parquet_file = 'clean_airfoil_data.parquet'\n",
    "df_cleaned.to_parquet(parquet_file)\n",
    "print(f\"Q5. Parquet file created: {parquet_file}\")\n",
    "\n",
    "# Q6: Rows in cleaned Parquet dataset\n",
    "df_parquet = pd.read_parquet(parquet_file)\n",
    "rows_parquet = len(df_parquet)\n",
    "print(\"Q6. Rows in cleaned Parquet dataset:\", rows_parquet)\n",
    "\n",
    "# Q7-Q10: Machine Learning Pipeline Stages\n",
    "\n",
    "target_column = 'PressureLevel'\n",
    "\n",
    "if target_column not in df_cleaned.columns:\n",
    "    print(f\"Error: Column '{target_column}' not found in the dataset.\")\n",
    "else:\n",
    "    # Features and target\n",
    "    X = df_cleaned.drop(columns=[target_column])\n",
    "    y = df_cleaned[target_column]\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Q11: Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(\"Q11. Mean Squared Error:\", mse)\n",
    "\n",
    "    # Q12: Mean Absolute Error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Q12. Mean Absolute Error:\", mae)\n",
    "\n",
    "    # Q13: R Squared\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"Q13. R Squared:\", r2)\n",
    "\n",
    "    # Q14: Intercept\n",
    "    intercept = model.intercept_\n",
    "    print(\"Q14. Intercept:\", intercept)\n",
    "\n",
    "    # Q15: Number of stages in pipeline\n",
    "    stages = ['Data Preprocessing', 'Model Training', 'Model Evaluation']\n",
    "    print(\"Q15. Number of stages in the pipeline:\", len(stages))\n",
    "\n",
    "    # Q16-Q20: Coefficients for each feature\n",
    "    coefficients = model.coef_\n",
    "    feature_names = X.columns\n",
    "\n",
    "    print(\"\\nQ16-Q20. Coefficients for each feature:\")\n",
    "    for feature, coef in zip(feature_names, coefficients):\n",
    "        print(f\"Coefficient for {feature}: {coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde895-c469-4011-b038-4d5079cad62d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27026b-3809-4c1a-bf28-028e38bc5053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
